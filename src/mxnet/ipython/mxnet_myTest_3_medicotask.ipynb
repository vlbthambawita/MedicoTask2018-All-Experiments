{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import copy # for deep copying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision.datasets import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet import gluon, nd, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/data_generated_medicotask_70_30_v2\" #main_data_dir\n",
    "\n",
    "train_data_dir = f'{data_dir}/train'\n",
    "validation_data_dir = f'{data_dir}/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(train_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = 224\n",
    "SIZE = (TARGET_SIZE, TARGET_SIZE)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4#multiprocessing.cpu_count()\n",
    "NUM_OF_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mxnet_optimization_test_1\"\n",
    "model_dir = data_dir + '/mxnet_models'\n",
    "plot_dir  = data_dir + '/mxnet_plots'\n",
    "history_dir = data_dir + '/mxnet_history'\n",
    "\n",
    "acc_loss_plot_name = 'acc_loss_plot_' + model_name\n",
    "\n",
    "train_data_dir = f'{data_dir}/train'\n",
    "validation_data_dir = f'{data_dir}/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.mkdir(plot_dir)\n",
    "\n",
    "if not os.path.exists(history_dir):\n",
    "    os.mkdir(history_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "     # resize the shorter edge to 224, the longer edge will be greater or equal to 224\n",
    "    resized = mx.image.resize_short(image, TARGET_SIZE)\n",
    "    # center and crop an area of size (224,224)\n",
    "    cropped, crop_info = mx.image.center_crop(resized, SIZE)\n",
    "    #transpose the channels to be (3,224,224)\n",
    "    transposed = nd.transpose(cropped, (2,0,1))\n",
    "    return transposed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolderDataset(root=train_data_dir, transform=transform)\n",
    "dataset_test = ImageFolderDataset(root=validation_data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 3697 images, Test dataset: 1596 images\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=NUM_WORKERS) # last_batch='discard' (removed for testing)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, # last_batch='discard',\n",
    "                             shuffle=True, num_workers=NUM_WORKERS)\n",
    "print(\"Train dataset: {} images, Test dataset: {} images\".format(len(dataset_train), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset_train.synsets\n",
    "NUM_CLASSES = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blurry-nothing',\n",
       " 'colon-clear',\n",
       " 'dyed-lifted-polyps',\n",
       " 'dyed-resection-margins',\n",
       " 'esophagitis',\n",
       " 'instruments',\n",
       " 'normal-cecum',\n",
       " 'normal-pylorus',\n",
       " 'normal-z-line',\n",
       " 'out-of-patient',\n",
       " 'polyps',\n",
       " 'retroflex-rectum',\n",
       " 'retroflex-stomach',\n",
       " 'stool-inclusions',\n",
       " 'stool-plenty',\n",
       " 'ulcerative-colitis']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.gluon.data.dataloader.DataLoader at 0x7f719fc70208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOdel creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained squeezenet\n",
    "net = models.resnet50_v2(pretrained=True, prefix='medico_task',ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = models.resnet50_v2(prefix='medico_task', classes=NUM_CLASSES, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.collect_params().initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.features = net.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#metric_loss = mx.metric.Loss()\n",
    "\n",
    "def evaluate_accuracy(data_iterator,loss_fn, net):\n",
    "    metric_acc = mx.metric.Accuracy()\n",
    "  #  numerator = 0.\n",
    "  #  denominator = 0.\n",
    "    cumulative_loss = mx.nd.zeros(1, ctx=ctx)\n",
    "    no_of_samples = mx.nd.zeros(1, ctx=ctx)\n",
    "\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        with autograd.predict_mode():\n",
    "            data = data.astype(np.float32).as_in_context(ctx)\n",
    "            label = label.astype(np.int32).as_in_context(ctx)\n",
    "            output = net(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            prediction = nd.argmax(output, axis=1).astype(np.int32)\n",
    "            cumulative_loss += nd.sum(loss).asscalar()\n",
    "            no_of_samples += data.shape[0]\n",
    "\n",
    "        metric_acc.update([label], [prediction])\n",
    "        #metric_loss.update([label], [prediction])\n",
    "    \n",
    "    \n",
    "    print(\"cumulative loss = {0} no_of_samples = {1}\" .format(cumulative_loss, no_of_samples))\n",
    "    loss = cumulative_loss / no_of_samples\n",
    "    return metric_acc.get()[1], loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative loss = \n",
      "[344.77698]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "out_acc, out_loss  = evaluate_accuracy(dataloader_test, softmax_cross_entropy, my_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266917293233082"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21602574"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_loss.asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridSequential(\n",
       "  (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=True, use_global_stats=False, in_channels=3)\n",
       "  (1): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "  (3): Activation(relu)\n",
       "  (4): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
       "  (5): HybridSequential(\n",
       "    (0): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv1): Conv2D(64 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "      (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (6): HybridSequential(\n",
       "    (0): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv1): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (1): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (7): HybridSequential(\n",
       "    (0): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv1): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (1): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (8): HybridSequential(\n",
       "    (0): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "      (conv1): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Conv2D(1024 -> 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (1): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "      (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BottleneckV2(\n",
       "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "      (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "      (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (9): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "  (10): Activation(relu)\n",
       "  (11): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
       "  (12): Flatten\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net.featu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ParameterDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-22fe46706448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'\"conv1\"'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ParameterDict' object is not callable"
     ]
    }
   ],
   "source": [
    "weights = my_net.params()[0]['\"conv1\"'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = my_net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medico_task (\n",
       "  Parameter medico_taskconv1 (shape=None, dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm0_gamma (shape=(3,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm0_beta (shape=(3,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm0_running_mean (shape=(3,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm0_running_var (shape=(3,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskconv0_weight (shape=(64, 3, 7, 7), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm1_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm1_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm1_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm1_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm0_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm0_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm0_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm0_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv0_weight (shape=(64, 64, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm1_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm1_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm1_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm1_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv1_weight (shape=(64, 64, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm2_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm2_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm2_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm2_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv2_weight (shape=(256, 64, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv3_weight (shape=(256, 64, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm3_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm3_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm3_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm3_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv4_weight (shape=(64, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm4_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm4_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm4_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm4_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv5_weight (shape=(64, 64, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm5_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm5_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm5_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm5_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv6_weight (shape=(256, 64, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm6_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm6_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm6_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm6_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv7_weight (shape=(64, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm7_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm7_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm7_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm7_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv8_weight (shape=(64, 64, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm8_gamma (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm8_beta (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm8_running_mean (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_batchnorm8_running_var (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage1_conv9_weight (shape=(256, 64, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm0_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm0_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm0_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm0_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv0_weight (shape=(128, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm1_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm1_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm1_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm1_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv1_weight (shape=(128, 128, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm2_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm2_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm2_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm2_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv2_weight (shape=(512, 128, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv3_weight (shape=(512, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm3_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm3_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm3_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm3_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv4_weight (shape=(128, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm4_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm4_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm4_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm4_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv5_weight (shape=(128, 128, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm5_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm5_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm5_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm5_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv6_weight (shape=(512, 128, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm6_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm6_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm6_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm6_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv7_weight (shape=(128, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm7_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm7_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm7_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm7_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv8_weight (shape=(128, 128, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm8_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm8_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm8_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm8_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv9_weight (shape=(512, 128, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm9_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm9_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm9_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm9_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv10_weight (shape=(128, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm10_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm10_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm10_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm10_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv11_weight (shape=(128, 128, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm11_gamma (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm11_beta (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm11_running_mean (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_batchnorm11_running_var (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage2_conv12_weight (shape=(512, 128, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm0_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm0_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm0_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm0_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv0_weight (shape=(256, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm1_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm1_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm1_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm1_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv1_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm2_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm2_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm2_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm2_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv2_weight (shape=(1024, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv3_weight (shape=(1024, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm3_gamma (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm3_beta (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm3_running_mean (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm3_running_var (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv4_weight (shape=(256, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm4_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm4_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm4_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm4_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv5_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm5_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm5_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm5_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm5_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv6_weight (shape=(1024, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm6_gamma (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm6_beta (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm6_running_mean (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm6_running_var (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv7_weight (shape=(256, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm7_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm7_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm7_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm7_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv8_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm8_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm8_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm8_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm8_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv9_weight (shape=(1024, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm9_gamma (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm9_beta (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm9_running_mean (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm9_running_var (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv10_weight (shape=(256, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm10_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm10_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm10_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm10_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv11_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm11_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm11_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm11_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm11_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv12_weight (shape=(1024, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm12_gamma (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm12_beta (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm12_running_mean (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm12_running_var (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv13_weight (shape=(256, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm13_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm13_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm13_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm13_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv14_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm14_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm14_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm14_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm14_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv15_weight (shape=(1024, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm15_gamma (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm15_beta (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm15_running_mean (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm15_running_var (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv16_weight (shape=(256, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm16_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm16_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm16_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm16_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv17_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm17_gamma (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm17_beta (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm17_running_mean (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_batchnorm17_running_var (shape=(256,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage3_conv18_weight (shape=(1024, 256, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm0_gamma (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm0_beta (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm0_running_mean (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm0_running_var (shape=(1024,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv0_weight (shape=(512, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm1_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm1_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm1_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm1_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv1_weight (shape=(512, 512, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm2_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm2_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm2_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm2_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv2_weight (shape=(2048, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv3_weight (shape=(2048, 1024, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm3_gamma (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm3_beta (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm3_running_mean (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm3_running_var (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv4_weight (shape=(512, 2048, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm4_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm4_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm4_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm4_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv5_weight (shape=(512, 512, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm5_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm5_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm5_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm5_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv6_weight (shape=(2048, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm6_gamma (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm6_beta (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm6_running_mean (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm6_running_var (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv7_weight (shape=(512, 2048, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm7_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm7_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm7_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm7_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv8_weight (shape=(512, 512, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm8_gamma (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm8_beta (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm8_running_mean (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_batchnorm8_running_var (shape=(512,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskstage4_conv9_weight (shape=(2048, 512, 1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm2_gamma (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm2_beta (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm2_running_mean (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskbatchnorm2_running_var (shape=(2048,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter medico_taskdense0_weight (shape=(16, 2048), dtype=float32)\n",
       "  Parameter medico_taskdense0_bias (shape=(16,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter medico_taskconv1 (shape=None, dtype=<class 'numpy.float32'>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mxnet.symbol' has no attribute 'deepcopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-f5a71937962d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mxnet.symbol' has no attribute 'deepcopy'"
     ]
    }
   ],
   "source": [
    "test = mx.sym.deepcopy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative loss = \n",
      "[344.77707]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Untrained network Test Accuracy: 0.9267 Test loss: 0.2160\n"
     ]
    }
   ],
   "source": [
    "out_acc, out_loss  = evaluate_accuracy(dataloader_test, softmax_cross_entropy, my_net)\n",
    "print(\"Untrained network Test Accuracy: {0:.4f} Test loss: {1:.4f}\"\n",
    "      .format(out_acc, out_loss.asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative loss = 465.36513662338257 no_of_samples = 1596\n",
      "Untrained network Test Accuracy: 0.9123 Test loss: 0.2916\n"
     ]
    }
   ],
   "source": [
    "out_acc, out_loss  = evaluate_accuracy(dataloader_test, softmax_cross_entropy, my_net)\n",
    "print(\"Untrained network Test Accuracy: {0:.4f} Test loss: {1:.4f}\"\n",
    "      .format(out_acc, out_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array_gpu = mx.nd.empty((3,2), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.    1.875]\n",
       " [0.    0.   ]\n",
       " [0.    0.   ]]\n",
       "<NDArray 3x2 @gpu(0)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative loss = 751.9391508102417 no_of_samples = 1596\n"
     ]
    }
   ],
   "source": [
    "test_array_gpu[0,0], test_array_gpu[0, 1] = evaluate_accuracy(dataloader_test, softmax_cross_entropy, my_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.8784461  0.47113982]\n",
       " [0.         0.        ]\n",
       " [0.         0.        ]]\n",
       "<NDArray 3x2 @gpu(0)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "WDECAY = 0.00001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(my_net.collect_params(), 'sgd', \n",
    "                        {'learning_rate': LEARNING_RATE,\n",
    "                         'wd':WDECAY,\n",
    "                         'momentum':MOMENTUM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = data_dir + '/mxnet_models'\n",
    "model_name = \"test_mxnet_model_v2_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, trainer, loss_fn, num_epochs = 1):\n",
    "    \n",
    "\n",
    "    #val_accuracy = 0\n",
    "    val_accuracy = mx.nd.zeros(1, ctx=ctx)\n",
    "   # df = pd.DataFrame(columns=['train_acc', 'train_loss', 'val_acc', 'val_loss'])\n",
    "    history = mx.nd.empty((num_epochs, 4), ctx=ctx) # 4 represents = train_acc, train_loss, val_acc, val_loss\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, label) in enumerate(dataloader_train):\n",
    "            data = data.astype(np.float32).as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            if i%20==0 and i >0:\n",
    "                print('Batch [{0}] loss: {1:.4f}'\n",
    "                      .format(i, loss.mean().asscalar()))\n",
    "\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "                loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "            \n",
    "            \n",
    "        nd.waitall() # wait at the end of the epoch    \n",
    "\n",
    "\n",
    "      #  train_accuracy, train_loss = evaluate_accuracy(dataloader_train, loss_fn, net)\n",
    "        history[epoch,0], history[epoch,1] = evaluate_accuracy(dataloader_train, loss_fn, net)\n",
    "       # new_val_accuracy, new_val_loss = evaluate_accuracy(dataloader_test, loss_fn, net)\n",
    "        history[epoch,2], history[epoch,3] = evaluate_accuracy(dataloader_test, loss_fn, net)\n",
    "        new_val_accuracy = history[epoch,2]\n",
    "    #    df2 = pd.DataFrame([[train_accuracy, train_loss, new_val_accuracy, new_val_loss]], \n",
    "     #                      columns=['train_acc', 'train_loss', 'val_acc', 'val_loss'])\n",
    "        #new_val_accuracy = evaluate_accuracy_gluon(dataloader_test, my_net) \n",
    "      #  print(\"all done\")\n",
    "     #   print(type(train_accuracy))\n",
    "     #   print(\"Epoch [{0}] Train accuracy {1:.4f} val Accuracy {2:.4f} \" \n",
    "     #        .format(epoch, train_accuracy, new_val_accuracy))\n",
    "     #   print(\"Epoch [{0}] Train loss {1:.4f} val loss {2:.4f} \" \n",
    "     #         .format(epoch, train_loss, new_val_loss))\n",
    "\n",
    "        # We perform early-stopping regularization, to prevent the model from overfitting\n",
    "   #     df = df.append(df2, ignore_index=True)\n",
    "        if new_val_accuracy > val_accuracy:\n",
    "            print('Validation accuracy is increasing.. saving the model')\n",
    "            best_model_name_temp = model_name + \"deep_copy\" + str(epoch)\n",
    "            \n",
    "           # my_net.save_parameters(os.path.join(model_dir, model_name_temp))\n",
    "            best_model = copy.deepcopy(net)\n",
    "            #break\n",
    "            val_accuracy = new_val_accuracy\n",
    "    \n",
    "    # at last: save the best model to HDD\n",
    "    best_model.save_parameters(os.path.join(model_dir, best_model_name_temp))\n",
    "    \n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0323\n",
      "Batch [40] loss: 0.0773\n",
      "Batch [60] loss: 0.0639\n",
      "Batch [80] loss: 0.1261\n",
      "Batch [100] loss: 0.0341\n",
      "cumulative loss = 60.652903348207474 no_of_samples = 3697\n",
      "cumulative loss = 60.65290443599224 no_of_samples = 3697\n",
      "cumulative loss = 347.2140165567398 no_of_samples = 1596\n",
      "cumulative loss = 347.2140169143677 no_of_samples = 1596\n",
      "all done\n",
      "<class 'numpy.float64'>\n",
      "Epoch [0] Train accuracy 0.9986 val Accuracy 0.9229 \n",
      "Epoch [0] Train loss 0.0164 val loss 0.2176 \n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 51.6 s, sys: 21.3 s, total: 1min 12s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   train_acc  train_loss   val_acc  val_loss\n",
       " 0   0.998648    0.016406  0.922932  0.217553, \n",
       " [[0.9986476  0.01640598 0.9229323  0.21755265]]\n",
       " <NDArray 1x4 @gpu(0)>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0248\n",
      "Batch [40] loss: 0.0293\n",
      "Batch [60] loss: 0.0510\n",
      "Batch [80] loss: 0.1492\n",
      "Batch [100] loss: 0.0387\n",
      "cumulative loss = 31.505593672394753 no_of_samples = 3697\n",
      "cumulative loss = 344.77702701091766 no_of_samples = 1596\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 38.2 s, sys: 16.1 s, total: 54.3 s\n",
      "Wall time: 50.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.99918854 0.00852193 0.9266917  0.21602571]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0163\n",
      "Batch [40] loss: 0.0115\n",
      "Batch [60] loss: 0.0282\n",
      "Batch [80] loss: 0.0239\n",
      "Batch [100] loss: 0.0122\n",
      "cumulative loss = \n",
      "[25.468235]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[3697.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "cumulative loss = \n",
      "[355.90643]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 38.3 s, sys: 16.3 s, total: 54.6 s\n",
      "Wall time: 50.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.99918854 0.00688889 0.92418545 0.22299902]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0087\n",
      "Batch [40] loss: 0.0131\n",
      "Batch [60] loss: 0.0138\n",
      "Batch [80] loss: 0.0436\n",
      "Batch [100] loss: 0.0237\n",
      "cumulative loss = \n",
      "[22.111965]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[3697.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "cumulative loss = \n",
      "[360.91272]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 38 s, sys: 15.6 s, total: 53.6 s\n",
      "Wall time: 50.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.999459   0.00598106 0.9235589  0.22613579]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0104\n",
      "Batch [40] loss: 0.0103\n",
      "Batch [60] loss: 0.0273\n",
      "Batch [80] loss: 0.0109\n",
      "Batch [100] loss: 0.0140\n",
      "cumulative loss = \n",
      "[16.213184]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[3697.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "cumulative loss = \n",
      "[356.77686]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 38.4 s, sys: 16.1 s, total: 54.5 s\n",
      "Wall time: 50.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.9997295  0.0043855  0.9254386  0.22354439]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0088\n",
      "Batch [40] loss: 0.0087\n",
      "Batch [60] loss: 0.0144\n",
      "Batch [80] loss: 0.0325\n",
      "Batch [100] loss: 0.0091\n",
      "cumulative loss = \n",
      "[13.436509]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[3697.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "cumulative loss = \n",
      "[351.14673]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 38.8 s, sys: 17.5 s, total: 56.3 s\n",
      "Wall time: 52.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.9997295  0.00363444 0.9285714  0.22001675]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0072\n",
      "Batch [40] loss: 0.0074\n",
      "Batch [60] loss: 0.0072\n",
      "Batch [80] loss: 0.0119\n",
      "Batch [100] loss: 0.0856\n",
      "cumulative loss = \n",
      "[12.45869]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[3697.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "cumulative loss = \n",
      "[356.69644]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 39.6 s, sys: 29.5 s, total: 1min 9s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.9997295  0.00336995 0.9273183  0.22349401]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0152\n",
      "Batch [40] loss: 0.0109\n",
      "Batch [60] loss: 0.0037\n",
      "Batch [80] loss: 0.0080\n",
      "Batch [100] loss: 0.0055\n",
      "cumulative loss = \n",
      "[11.954583]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[3697.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "cumulative loss = \n",
      "[353.07568]\n",
      "<NDArray 1 @gpu(0)> no_of_samples = \n",
      "[1596.]\n",
      "<NDArray 1 @gpu(0)>\n",
      "Validation accuracy is increasing.. saving the model\n",
      "CPU times: user 40 s, sys: 30.4 s, total: 1min 10s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.9997295  0.00323359 0.92418545 0.22122537]]\n",
       "<NDArray 1x4 @gpu(0)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cpu = history.as_in_context(mx.cpu()).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9997295 , 0.00323359, 0.92418545, 0.22122537]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = data_dir + '/mxnet_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test_mxnet_model_v1_96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.save_parameters(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing trainign and validation accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.load_parameters(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " def run_batch(net, data):\n",
    "    results = []\n",
    "    for batch in data:\n",
    "        outputs = net(batch)\n",
    "        results.extend([o for o in outputs.asnumpy()])\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run_batch(my_net, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = mx.nd.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mx.nd.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = mx.ndarray.concat(true_labels, temp, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = mx.metric.Accuracy()\n",
    "\n",
    "all_true_labels = np.array([])#mx.nd.array([0])\n",
    "#temp = mx.nd.array([1,2,3,4,5])\n",
    "#all_predicted_labels = []\n",
    "all_predicted_labels_device = mx.nd.array([-1], ctx=ctx) # mx.nd\n",
    "\n",
    "\n",
    "for i,(data, label) in enumerate(dataloader_test):\n",
    "    \n",
    "    data = data.astype(np.float32).as_in_context(ctx) # loading data to GPU if available\n",
    "    l = label.asnumpy()\n",
    "    # label = label #.as_in_context(ctx) # loading data to GPU if available\n",
    "   # all_true_labels = mx.ndarray.concat(all_true_labels,l, dim=0 )\n",
    "    all_true_labels = np.concatenate((all_true_labels,l))\n",
    "    print(l)\n",
    "    print(\"====\")\n",
    "    print(label)\n",
    "    print(\"====\")\n",
    "    print(len(all_true_labels))\n",
    "    \n",
    "    with autograd.predict_mode():\n",
    "        probability=my_net(data)\n",
    "        predictions = nd.argmax(probability, axis=1)\n",
    "        all_predicted_labels_device = mx.ndarray.concat(all_predicted_labels_device, predictions, dim=0)\n",
    "        print(predictions)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "      #  print(acc.get()[1])\n",
    "        #all_true_labels.extend(label)\n",
    "       \n",
    "        #all_predicted_labels.extend(predictions)\n",
    "        print(\"gpu array =\",all_predicted_labels_device)\n",
    "      #  print(label)\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_cpu = all_predicted_labels_device.as_in_context(mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_cpu = all_predicted_labels_cpu[1:].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate confusion matrix\n",
    "cm = confusion_matrix(all_true_labels, all_predicted_labels_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (data, label) in enumerate(dataloader_t):\n",
    " # with autograd.predict_mode():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, dir, plt_name):\n",
    "    train_acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    df = pd.DataFrame({'train_acc':train_acc, 'train_loss':train_loss, 'val_acc':val_acc, 'val_loss':val_loss})\n",
    "    pie = df.plot()\n",
    "    fig = pie.get_figure()\n",
    "    #fig.savefig(os.path.join(plot_dir, acc_loss_plot_name))\n",
    "    fig.savefig(os.path.join(dir, plt_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          plt_size=[10,10]):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = plt_size\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.join(plot_dir, cm_plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir  = data_dir + '/mxnet_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_name = 'cm_'+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes=categories, title='my confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision.datasets import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet import gluon, nd, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/data_generated_medicotask_70_30_v2\" #main_data_dir\n",
    "\n",
    "train_data_dir = f'{data_dir}/train'\n",
    "validation_data_dir = f'{data_dir}/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(train_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = 224\n",
    "SIZE = (TARGET_SIZE, TARGET_SIZE)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4#multiprocessing.cpu_count()\n",
    "NUM_OF_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = data_dir + '/mxnet_models'\n",
    "plot_dir  = data_dir + '/mxnet_plots'\n",
    "history_dir = data_dir + '/mxnet_history'\n",
    "\n",
    "acc_loss_plot_name = 'acc_loss_plot_' + model_name\n",
    "\n",
    "train_data_dir = f'{data_dir}/train'\n",
    "validation_data_dir = f'{data_dir}/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.mkdir(plot_dir)\n",
    "\n",
    "if not os.path.exists(history_dir):\n",
    "    os.mkdir(history_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "     # resize the shorter edge to 224, the longer edge will be greater or equal to 224\n",
    "    resized = mx.image.resize_short(image, TARGET_SIZE)\n",
    "    # center and crop an area of size (224,224)\n",
    "    cropped, crop_info = mx.image.center_crop(resized, SIZE)\n",
    "    #transpose the channels to be (3,224,224)\n",
    "    transposed = nd.transpose(cropped, (2,0,1))\n",
    "    return transposed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolderDataset(root=train_data_dir, transform=transform)\n",
    "dataset_test = ImageFolderDataset(root=validation_data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 3697 images, Test dataset: 1596 images\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=NUM_WORKERS) # last_batch='discard' (removed for testing)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, # last_batch='discard',\n",
    "                             shuffle=True, num_workers=NUM_WORKERS)\n",
    "print(\"Train dataset: {} images, Test dataset: {} images\".format(len(dataset_train), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset_train.synsets\n",
    "NUM_CLASSES = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blurry-nothing',\n",
       " 'colon-clear',\n",
       " 'dyed-lifted-polyps',\n",
       " 'dyed-resection-margins',\n",
       " 'esophagitis',\n",
       " 'instruments',\n",
       " 'normal-cecum',\n",
       " 'normal-pylorus',\n",
       " 'normal-z-line',\n",
       " 'out-of-patient',\n",
       " 'polyps',\n",
       " 'retroflex-rectum',\n",
       " 'retroflex-stomach',\n",
       " 'stool-inclusions',\n",
       " 'stool-plenty',\n",
       " 'ulcerative-colitis']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.gluon.data.dataloader.DataLoader at 0x7f8aff674cf8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOdel creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained squeezenet\n",
    "net = models.resnet50_v2(pretrained=True, prefix='medico_task',ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = models.resnet50_v2(prefix='medico_task', classes=NUM_CLASSES, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.collect_params().initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.features = net.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = mx.metric.Accuracy()\n",
    "#metric_loss = mx.metric.Loss()\n",
    "\n",
    "def evaluate_accuracy(data_iterator,loss_fn, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    cumulative_loss = 0.\n",
    "    no_of_samples = 0\n",
    "\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        with autograd.record():\n",
    "            data = data.astype(np.float32).as_in_context(ctx)\n",
    "            label = label.astype(np.int32).as_in_context(ctx)\n",
    "            output = net(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            prediction = nd.argmax(output, axis=1).astype(np.int32)\n",
    "            cumulative_loss += nd.sum(loss).asscalar()\n",
    "            no_of_samples += data.shape[0]\n",
    "\n",
    "        metric_acc.update([label], [prediction])\n",
    "        #metric_loss.update([label], [prediction])\n",
    "    \n",
    "    \n",
    "    print(\"cumulative loss = {0} no_of_samples = {1}\" .format(cumulative_loss, no_of_samples))\n",
    "    loss = cumulative_loss / no_of_samples\n",
    "    return (metric_acc.get()[1], loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained network Test Accuracy: 0.1021\n"
     ]
    }
   ],
   "source": [
    "print(\"Untrained network Test Accuracy: {0:.4f}\".format(evaluate_accuracy_gluon(dataloader_test, my_net)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "WDECAY = 0.00001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(my_net.collect_params(), 'sgd', \n",
    "                        {'learning_rate': LEARNING_RATE,\n",
    "                         'wd':WDECAY,\n",
    "                         'momentum':MOMENTUM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = data_dir + '/mxnet_models'\n",
    "model_name = \"test_mxnet_model_v2_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, trainer, loss_fn, num_epochs = 1):\n",
    "    \n",
    "\n",
    "    val_accuracy = 0\n",
    "    df = pd.DataFrame(columns=['train_acc', 'train_loss', 'val_acc', 'val_loss'])\n",
    "    history = mx.nd.empty((num_epochs, 4), ctx=ctx) # 4 represents = train_acc, train_loss, val_acc, val_loss\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, label) in enumerate(dataloader_train):\n",
    "            data = data.astype(np.float32).as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            if i%20==0 and i >0:\n",
    "                print('Batch [{0}] loss: {1:.4f}'\n",
    "                      .format(i, loss.mean().asscalar()))\n",
    "\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "                loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "            \n",
    "            \n",
    "        nd.waitall() # wait at the end of the epoch    \n",
    "\n",
    "\n",
    "        train_accuracy, train_loss = evaluate_accuracy(dataloader_train, loss_fn, net)\n",
    "        history[epoch,0], history[epoch,1] = evaluate_accuracy(dataloader_train, loss_fn, net)\n",
    "        new_val_accuracy, new_val_loss = evaluate_accuracy(dataloader_test, loss_fn, net)\n",
    "        df2 = pd.DataFrame([[train_accuracy, train_loss, new_val_accuracy, new_val_loss]], \n",
    "                           columns=['train_acc', 'train_loss', 'val_acc', 'val_loss'])\n",
    "        #new_val_accuracy = evaluate_accuracy_gluon(dataloader_test, my_net) \n",
    "        print(\"all done\")\n",
    "        print(type(train_accuracy))\n",
    "        print(\"Epoch [{0}] Train accuracy {1:.4f} val Accuracy {2:.4f} \" \n",
    "              .format(epoch, train_accuracy, new_val_accuracy))\n",
    "        print(\"Epoch [{0}] Train loss {1:.4f} val loss {2:.4f} \" \n",
    "              .format(epoch, train_loss, new_val_loss))\n",
    "\n",
    "        # We perform early-stopping regularization, to prevent the model from overfitting\n",
    "        df = df.append(df2, ignore_index=True)\n",
    "        if new_val_accuracy > val_accuracy:\n",
    "            print('Validation accuracy is increasing.. saving the model')\n",
    "            model_name_temp = model_name + str(epoch)\n",
    "            my_net.save_parameters(os.path.join(model_dir, model_name_temp))\n",
    "            #break\n",
    "            val_accuracy = new_val_accuracy\n",
    "\n",
    "    return df, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20] loss: 0.0544\n",
      "Batch [40] loss: 0.0657\n",
      "Batch [60] loss: 0.0743\n",
      "Batch [80] loss: 0.0480\n",
      "Batch [100] loss: 0.0387\n",
      "cumulative loss = 216.37376481294632 no_of_samples = 3697\n",
      "cumulative loss = 402.71828842163086 no_of_samples = 1596\n",
      "all done\n",
      "<class 'numpy.float64'>\n",
      "Epoch [0] Train accuracy 0.9186 val Accuracy 0.9452 \n",
      "Epoch [0] Train loss 0.2154 val loss 0.2523 \n",
      "Validation accuracy is increasing.. saving the model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   train_acc  train_loss   val_acc  val_loss\n",
       " 0   0.918576    0.215397  0.945173   0.25233, \n",
       " [[ 0.9470425   0.05852685 11.035341    8.287036  ]]\n",
       " <NDArray 1x4 @gpu(0)>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(my_net, trainer=trainer, loss_fn=softmax_cross_entropy, num_epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.02706233 0.06010445 0.6718183  1.8139207  0.15482205 1.2854834\n",
       " 0.35737458 0.92547107 0.00485254 0.14731164 0.04010026 0.61669475\n",
       " 0.01689799 0.29015195 0.03917758 0.03056033 1.2022718 ]\n",
       "<NDArray 17 @gpu(0)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = data_dir + '/mxnet_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test_mxnet_model_v1_96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.save_parameters(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing trainign and validation accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net.load_parameters(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " def run_batch(net, data):\n",
    "    results = []\n",
    "    for batch in data:\n",
    "        outputs = net(batch)\n",
    "        results.extend([o for o in outputs.asnumpy()])\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run_batch(my_net, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = mx.nd.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mx.nd.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = mx.ndarray.concat(true_labels, temp, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = mx.metric.Accuracy()\n",
    "\n",
    "all_true_labels = np.array([])#mx.nd.array([0])\n",
    "#temp = mx.nd.array([1,2,3,4,5])\n",
    "#all_predicted_labels = []\n",
    "all_predicted_labels_device = mx.nd.array([-1], ctx=ctx) # mx.nd\n",
    "\n",
    "\n",
    "for i,(data, label) in enumerate(dataloader_test):\n",
    "    \n",
    "    data = data.astype(np.float32).as_in_context(ctx) # loading data to GPU if available\n",
    "    l = label.asnumpy()\n",
    "    # label = label #.as_in_context(ctx) # loading data to GPU if available\n",
    "   # all_true_labels = mx.ndarray.concat(all_true_labels,l, dim=0 )\n",
    "    all_true_labels = np.concatenate((all_true_labels,l))\n",
    "    print(l)\n",
    "    print(\"====\")\n",
    "    print(label)\n",
    "    print(\"====\")\n",
    "    print(len(all_true_labels))\n",
    "    \n",
    "    with autograd.predict_mode():\n",
    "        probability=my_net(data)\n",
    "        predictions = nd.argmax(probability, axis=1)\n",
    "        all_predicted_labels_device = mx.ndarray.concat(all_predicted_labels_device, predictions, dim=0)\n",
    "        print(predictions)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "      #  print(acc.get()[1])\n",
    "        #all_true_labels.extend(label)\n",
    "       \n",
    "        #all_predicted_labels.extend(predictions)\n",
    "        print(\"gpu array =\",all_predicted_labels_device)\n",
    "      #  print(label)\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_cpu = all_predicted_labels_device.as_in_context(mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_cpu = all_predicted_labels_cpu[1:].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate confusion matrix\n",
    "cm = confusion_matrix(all_true_labels, all_predicted_labels_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (data, label) in enumerate(dataloader_t):\n",
    " # with autograd.predict_mode():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, dir, plt_name):\n",
    "    train_acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    df = pd.DataFrame({'train_acc':train_acc, 'train_loss':train_loss, 'val_acc':val_acc, 'val_loss':val_loss})\n",
    "    pie = df.plot()\n",
    "    fig = pie.get_figure()\n",
    "    #fig.savefig(os.path.join(plot_dir, acc_loss_plot_name))\n",
    "    fig.savefig(os.path.join(dir, plt_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          plt_size=[10,10]):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = plt_size\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.join(plot_dir, cm_plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir  = data_dir + '/mxnet_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_name = 'cm_'+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes=categories, title='my confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

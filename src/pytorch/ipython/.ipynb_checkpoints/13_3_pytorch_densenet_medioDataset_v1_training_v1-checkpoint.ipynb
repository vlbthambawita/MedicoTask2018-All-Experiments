{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch - Densnet201 - 16 classes - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "#  ######################################################\n",
    "#  #### Matplotlib X display error - removing for server#\n",
    "#  ######################################################\n",
    "mpl.use('Agg')  # This has to run before pyplot import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets # for ipython widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take date and time for saving points\n",
    "now = datetime.datetime.now()\n",
    "date_and_time = now.strftime(\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial varaibles to change for different running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_dir = \"../../../data/data_generated_medicotask_70_30_v2\"  # Main data directory to be handled\n",
    "model_name = date_and_time + \"_13_3_densenet201_70_30\"\n",
    "checkpoint_name_format = date_and_time + \"_13_3_weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of epochs and batchsize (to be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 1\n",
    "\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories to save output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = main_data_dir\n",
    "model_dir = data_dir + '/pytorch_models'\n",
    "plot_dir  = data_dir + '/pytorch_plots'\n",
    "history_dir = data_dir + '/pytorch_history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_loss_plot_name = 'acc_loss_plot_' + model_name\n",
    "accuracy_plot_name = 'accuracy_plot_' + model_name\n",
    "loss_plot_name = 'loss_plot_' + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#  Managin Directory structure\n",
    "########################################################################\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.mkdir(plot_dir)\n",
    "\n",
    "if not os.path.exists(history_dir):\n",
    "    os.mkdir(history_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.listdir(main_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data - Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(229),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(90),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(229),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'validation']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=1)\n",
    "               for x in ['train', 'validation']}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the computing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main method to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history_tensor = torch.empty((num_epochs, 4), device=device)  # 4- trai_acc, train_loss, val_acc, val_loss\n",
    "    checkpoint_name = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            indicator = 0  # just for print batch processing status (no of batches)\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                  #  print(\"outputs=\", outputs) # only for testing - vajira\n",
    "                  #  print(\"labels = \", labels) # only for testing - vajira\n",
    "                    print(indicator, sep='-', end='=', flush=True)\n",
    "                    indicator += 1\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Collecting data for making plots\n",
    "            if phase == 'train':\n",
    "                history_tensor[epoch, 0] = epoch_acc\n",
    "                history_tensor[epoch, 1] = epoch_loss\n",
    "            if phase == 'validation':\n",
    "                history_tensor[epoch, 2] = epoch_acc\n",
    "                history_tensor[epoch, 3] = epoch_loss\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                checkpoint_name = checkpoint_name_format.format(epoch=epoch, val_acc=best_acc)\n",
    "                print(\"Found a best model:\", checkpoint_name)\n",
    "            elif phase== 'validation':\n",
    "                print(\"No improvement from the previous best model \")\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history_tensor, checkpoint_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A methods to plot and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#  Ploting history and save plots to plots directory\n",
    "###########################################################\n",
    "def plot_and_save_training_history(history_tensor):\n",
    "    history_data = history_tensor.cpu().numpy()\n",
    "    df = pd.DataFrame(history_data, columns=['train_acc', 'train_loss', 'val_acc', 'val_loss'])\n",
    "    pie = df.plot()\n",
    "    fig = pie.get_figure()\n",
    "    fig.savefig(os.path.join(plot_dir, \"_training_\" + acc_loss_plot_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained mode and modifying the last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajira/.local/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.densenet201(pretrained=False) # without pretrained weights\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Setting model parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If multiple GPUs are there, then use all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found only one GPU\n"
     ]
    }
   ],
   "source": [
    "## #######################################################\n",
    "# If multiple GPUS are there, run on multiple GPUS\n",
    "##########################################################\n",
    "#  Setting model in multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model_ft = nn.DataParallel(model_ft)\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    print(\"Found only one GPU\")\n",
    "else:\n",
    "    print(\"No GPU.. Runing on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model to the GPUs and run it to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "0=1=2=3=4=5=6=7=8=9=10=11=12=13=14=15=16=17=18=19=20=21=22=23=24=25=26=27=28=29=30=31=32=33=34=35=36=37=38=39=40=41=42=43=44=45=46=47=48=49=50=51=52=53=54=55=56=57=58=59=60=61=62=63=64=65=66=67=68=69=70=71=72=73=74=75=76=77=78=79=80=81=82=83=84=85=86=87=88=89=90=91=92=93=94=95=96=97=98=99=100=101=102=103=104=105=106=107=108=109=110=111=112=113=114=115=116=117=118=119=120=121=122=123=124=125=126=127=128=129=130=131=132=133=134=135=136=137=138=139=140=141=142=143=144=145=146=147=train Loss: 1.6422 Acc: 0.4011\n",
      "0=1=2=3=4=5=6=7=8=9=10=11=12=13=14=15=16=17=18=19=20=21=22=23=24=25=26=27=28=29=30=31=32=33=34=35=36=37=38=39=40=41=42=43=44=45=46=47=48=49=50=51=52=53=54=55=56=57=58=59=60=61=62=63=validation Loss: 1.4097 Acc: 0.4317\n",
      "Found a best model: 201808201525_13_3_weights-improvement-00-0.4317.hdf5\n",
      "\n",
      "Training complete in 2m 2s\n",
      "Best val Acc: 0.431704\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#  Loading model to GPUs and setting parameters\n",
    "##############################################################\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "### start Training\n",
    "############################################################\n",
    "\n",
    "model_ft, history_tensor, check_point_name = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=number_of_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best model to the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201808201525_13_3_weights-improvement-00-0.4317.hdf5\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "### Save the model to the directory\n",
    "############################################################\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)  # to save plots\n",
    "\n",
    "if not check_point_name==None:\n",
    "    print(check_point_name)\n",
    "    torch.save(model_ft.state_dict(), os.path.join(model_dir, check_point_name))\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and save training history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved to ../../../data/data_generated_medicotask_70_30_v2/pytorch_plots\n"
     ]
    }
   ],
   "source": [
    "plot_and_save_training_history(history_tensor)\n",
    "\n",
    "print(\"Plots saved to\", plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model to retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take date and time for saving points\n",
    "now = datetime.datetime.now()\n",
    "date_and_time = now.strftime(\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weight_file_name = input('Please, enter the best weights value file name:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(torch.load(os.path.join(model_dir, best_weight_file_name)))\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
